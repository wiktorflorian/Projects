{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "<h1 style=\"color: #FFC0CB; font-size: 24px;\">\n",
    "CSV_DIVIDER CONCEPT\n",
    "</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to divide by 100mb my csv file with table structured data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def split_csv(file_path, output_folder, max_file_size_mb, delimiter=';'):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path, delimiter=delimiter)\n",
    "\n",
    "    # Calculating chunk size\n",
    "    max_file_size = max_file_size_mb * 1000 * 1000\n",
    "\n",
    "    # Initialize variables\n",
    "    current_file_size = 0\n",
    "    current_chunk = 1\n",
    "    output_file = os.path.join(output_folder, f\"chunk_{current_chunk}.csv\")\n",
    "\n",
    "    # Write the header row to each output file\n",
    "    pd.DataFrame(df.columns).to_csv(output_file, index=False)\n",
    "\n",
    "    # iterate over rows and split into chunks\n",
    "    with open(output_file, 'a') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            row_str = delimiter.join([str(val) for val in row.values]) + '\\n'\n",
    "            row_size = len(row_str)\n",
    "\n",
    "            # Check if adding the row exceeds the maximum file size\n",
    "            if current_file_size + row_size > max_file_size:\n",
    "                f.close()\n",
    "                print(f\"Saved {current_chunk} / x\")\n",
    "\n",
    "                # Increment chunk number\n",
    "                current_chunk += 1\n",
    "                output_file = os.path.join(output_folder, f\"chunk_{current_chunk}.csv\")\n",
    "\n",
    "                # Write the header row to the new output file\n",
    "                pd.DataFrame(df.columns).to_csv(output_file, index=False)\n",
    "\n",
    "                # Open new file for writing\n",
    "                f = open(output_file, 'a')\n",
    "\n",
    "                # Reset the current file size\n",
    "                current_file_size = 0\n",
    "            \n",
    "            # Write the row to the chunk\n",
    "            f.write(row_str)\n",
    "\n",
    "            # Update the current file size\n",
    "            current_file_size += row_size        \n",
    "    print(f\"Saved {current_chunk} chunks.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 / x\n",
      "Saved 2 chunks.\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"input\", \"amazon.csv\")\n",
    "output_path = os.path.join(os.getcwd(),\"output\")\n",
    "max_file_size_mb = 75\n",
    "\n",
    "split_csv(file_path, output_path, max_file_size_mb, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.52557373046875\n"
     ]
    }
   ],
   "source": [
    "my_ch = 75 * 1000 * 1000\n",
    "ch = 75 * 1024 * 1024\n",
    "\n",
    "print(my_ch / 1024 / 1024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(os.getcwd(), \"output/chunk_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(test_path, delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:935\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[39mdel\u001b[39;00m kwds[\u001b[39m\"\u001b[39m\u001b[39mfilepath_or_buffer\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[39mdel\u001b[39;00m kwds[\u001b[39m\"\u001b[39m\u001b[39msep\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[1;32m    938\u001b[0m     delim_whitespace,\n\u001b[1;32m    939\u001b[0m     engine,\n\u001b[1;32m    940\u001b[0m     sep,\n\u001b[1;32m    941\u001b[0m     error_bad_lines,\n\u001b[1;32m    942\u001b[0m     warn_bad_lines,\n\u001b[1;32m    943\u001b[0m     on_bad_lines,\n\u001b[1;32m    944\u001b[0m     names,\n\u001b[1;32m    945\u001b[0m     prefix,\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mdelimiter\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m    950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:2063\u001b[0m, in \u001b[0;36m_refine_defaults_read\u001b[0;34m(dialect, delimiter, delim_whitespace, engine, sep, error_bad_lines, warn_bad_lines, on_bad_lines, names, prefix, defaults)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2058\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSpecified a delimiter with both sep and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2059\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdelim_whitespace=True; you can only specify one.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2060\u001b[0m     )\n\u001b[1;32m   2062\u001b[0m \u001b[39mif\u001b[39;00m delimiter \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 2063\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2064\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSpecified \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mn as separator or delimiter. This forces the python engine \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2065\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwhich does not accept a line terminator. Hence it is not allowed to use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2066\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe line terminator as separator.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2067\u001b[0m     )\n\u001b[1;32m   2069\u001b[0m \u001b[39mif\u001b[39;00m delimiter \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n\u001b[1;32m   2070\u001b[0m     \u001b[39m# assign default separator value\u001b[39;00m\n\u001b[1;32m   2071\u001b[0m     kwds[\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m delim_default\n",
      "\u001b[0;31mValueError\u001b[0m: Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator."
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(test_path, delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
